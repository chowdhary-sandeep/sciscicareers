{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4fad24-7943-4e16-937a-8fb69a151439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 8, 'font.style': 'normal', 'font.family':'serif'})\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "def simpleaxis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    plt.xticks(fontsize=ff-4)\n",
    "    plt.yticks(fontsize=ff-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949f8c52-ca6a-49f5-b76d-9b54b6fbc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "path_data=\"/mnt/sdb1/sandeep/\"\n",
    "path_career=path_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815bb492-2338-4168-b1dd-05e4b37faefd",
   "metadata": {},
   "source": [
    "# Loading paper-author data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eacfd020-ac71-49a6-9762-62deec1ba732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.32244236767292\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "# names=path_data+'openalex_ACTIV/pap_auth_wc20/*'\n",
    "names=path_data+'openalex_ACTIV/2paperauthors_nopreprints_filtered_teamsize10_wc20and400_wcperyearexists/*'\n",
    "# names=path_data+'openalex_ACTIV/2authorspapers_statphy/*'\n",
    "\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=15)\n",
    "df_new_by_papers = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "p.close()\n",
    "df_new_by_papers.columns=['a','b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f362ac7c-938d-4182-8f27-2521c815b7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4069cba1-f357-4ce3-a12e-6710463fa71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_auth_to_paper=df_new_by_papers.groupby('a')['b'].apply(list).to_dict()\n",
    "with open(path_career+'dict_auth_to_paper(whole).pkl', 'wb') as f:\n",
    "    pickle.dump(dict_auth_to_paper, f)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58edc991-ef50-4e19-ba24-42e9712e83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_paper_to_auth=df_new_by_papers.groupby('b')['a'].apply(list).to_dict()\n",
    "with open(path_career+'dict_paper_to_auth(whole).pkl', 'wb') as f:\n",
    "    pickle.dump(dict_paper_to_auth, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7e0469-4ca6-43c4-a84c-e365da7c28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "# with open(path_career+'dict_auth_N_ord3.pkl', 'rb') as f:\n",
    "#     dict_auth_N_ord3=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0016c434-57ef-46fb-9de6-b1e43e852ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ord3=pd.read_csv(path_career+'2auth_ord3_papercount.csv') \n",
    "dict_auth_N_ord3=df_ord3.set_index('aid1')['f0_'].T.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd446f2a-2b87-4c2c-acf5-9b89281ec899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4004817"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_auth_N_ord3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0246e2c-211c-4800-92a0-de49345b5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(path_career+'dict_authwc_after_year_x.pkl', 'rb') as f:\n",
    "    dict_authwc_after_year_x=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9a3931-22dc-4131-80fc-42030bf349bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000926"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_authwc_after_year_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fef6233-3610-4c91-887f-b717b200f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_authwc_after_year_x['https://openalex.org/A2764379743']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129aa25b-059d-435d-8119-e918b3a27c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e441d41-7a35-4190-bf30-f378623e7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_career+'dict_firstpub.pkl', 'rb') as f:\n",
    "    dict_firstpub=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d4f085-763d-4e14-aab0-49f1eb608017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8851776"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_firstpub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf0b39-e823-4db2-a607-c9cd3995a555",
   "metadata": {},
   "source": [
    "# Run svs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ba8c3e-9bd4-459d-8d85-1498faa69fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter,defaultdict,OrderedDict\n",
    "from itertools import combinations\n",
    "import numpy as np \n",
    "from multiprocessing import Pool,cpu_count\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import binom\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "#sns.set_style('white')\n",
    "sns.set_context('talk')#, font_scale=1.5)\n",
    "import matplotlib as mpl\n",
    "# mpl.rcParams.update({'text.usetex': False})\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "# register_matplotlib_converters()\n",
    "\n",
    "def p_over(t):\n",
    "    w,n,na,nb = t\n",
    "    return st.hypergeom.sf(w-1,n,na,nb)\n",
    "\n",
    "def p_appr(t):\n",
    "    n12 = t[0]\n",
    "    n = t[1]\n",
    "    ns = np.array(t[2:])\n",
    "    order = len(ns)\n",
    "    p = st.binom.sf(n12-1,p=np.prod(ns/n),n=n)\n",
    "    if p>=0:\n",
    "        return p\n",
    "    else:\n",
    "        print(n12,n,ns)\n",
    "        return p\n",
    "    \n",
    "    \n",
    "def tpr(true,pred):\n",
    "    return len(set(pred).intersection(true))/len(true)\n",
    "\n",
    "def fdr(true,pred):\n",
    "    try:\n",
    "        return len(set(pred).difference(true))/len(pred)\n",
    "    except: return np.nan\n",
    "def jaccard(true,pred):\n",
    "    return len(set(true).intersection(pred))/len(set(true).union(pred))\n",
    "\n",
    "def expand(x,order):\n",
    "    return tuple(combinations(x,order))\n",
    "\n",
    "def expand_filter(x,order,drop):\n",
    "    return list(set(combinations(x,order)).difference(drop))\n",
    "\n",
    "def tuple_to_validate(x,groups,N,deg_a):\n",
    "    return tuple([groups[x],N])+tuple([deg_a[ii] for ii in x])\n",
    "\n",
    "\n",
    "def get_svs(df,dict_auth_N_ord3,dict_authwc_after_year_x,dict_firstpub,min_order=2,max_order=10,approximate=True):\n",
    "\n",
    "\n",
    "    observables = df.groupby('b')['a'].apply(lambda x: tuple(sorted(x))).tolist()\n",
    "    print(len(observables))\n",
    "\n",
    "    if max_order!=0:\n",
    "        max_order = min(max_order,max(map(len,observables)))\n",
    "    else:\n",
    "        max_order = max(map(len,observables))\n",
    "    #     max_order=10\n",
    "    print(max_order)\n",
    "\n",
    "    s_groups = []\n",
    "\n",
    "    neigh_set_a_sub = dict(df.groupby('a')['b'].apply(list).reset_index().values) \n",
    "    N = df.b.nunique()\n",
    "    na = df.a.nunique()\n",
    "\n",
    "    if approximate: deg_a = Counter(df.a)\n",
    "\n",
    "    significant_cores3 = []\n",
    "    nonsignificant_cores3 = []\n",
    "    groups_higher_order = {}\n",
    "\n",
    "    t_ic = time.time();\n",
    "    for order in list(range(min_order,max_order+1))[::-1]:\n",
    "    # for order in range(4,5):\n",
    "        t_oc = time.time();\n",
    "        print(order, '---- ',str(round(t_oc-t_ic,2)))\n",
    "\n",
    "        expand_order = partial(expand,order=order) \n",
    "\n",
    "        order_obs = filter(lambda x: len(x)>=order,s_groups)\n",
    "        #p = Pool(processes=cpu_count())\n",
    "        B = (i for ii in map(expand_order,order_obs) for i in ii)\n",
    "        drop = Counter(B)\n",
    "        #p.close()\n",
    "\n",
    "        expand_filter_order = partial(expand_filter,order=order,drop=drop)\n",
    "        print('drop')\n",
    "        if not approximate:\n",
    "\n",
    "            groups = set()\n",
    "            for l in (map(lambda x: tuple(combinations(x,order)), filter(lambda x: len(x)>=order,observables))): \n",
    "                for g in l: groups.add(g)\n",
    "            groups = groups.difference(drop)\n",
    "\n",
    "        else:\n",
    "\n",
    "\n",
    "            order_obs = filter(lambda x: len(x)>=order,observables)\n",
    "            #p = Pool(processes=cpu_count())\n",
    "            B = (i for ii in map(expand_order,order_obs) for i in ii)\n",
    "            groups = Counter(B)\n",
    "\n",
    "\n",
    "\n",
    "            for g in drop: del groups[g]\n",
    "\n",
    "\n",
    "                # MAKE DICTIONARY\n",
    "                # YEAR_YOUNGEST=np.max ([dict_first_paper_year[x] for x in g])\n",
    "\n",
    "\n",
    "        print(len(groups))\n",
    "        print('dropped')\n",
    "\n",
    "\n",
    "        dict_YEAR_YOUNGEST_START={}\n",
    "        t_ic = time.time();\n",
    "        it_auth=0\n",
    "        for auths in list(groups.keys()):\n",
    "            dict_YEAR_YOUNGEST_START[auths]= np.max([dict_firstpub[auth] for auth in auths])\n",
    "            it_auth+=1\n",
    "            if (it_auth+1)%1000==0:\n",
    "                t_oc = time.time();\n",
    "                frac=it_auth/len(groups)\n",
    "                prog=str(frac)+str(round(t_oc-t_ic,2))+', time estimate: '+str(round((t_oc-t_ic)/frac/3600,2))\n",
    "                print(prog,end='\\r')\n",
    "\n",
    "\n",
    "        #print(len(groups))\n",
    "        p = Pool(processes=cpu_count())\n",
    "    #         p = Pool(processes=8)\n",
    "        if not approximate:\n",
    "\n",
    "            pvalues = dict(zip(groups,p.map(pvalue_intersect,zip(groups,[neigh_set_a_sub]*len(groups),[N]*len(groups)))))\n",
    "        else:\n",
    "    #             pvalues = dict(zip(groups,p.map(p_appr,[tuple([groups[i],sum([dict_auth_N_ord3[x] for x in i])])+tuple([deg_a[ii] for ii in i]) for i in groups])))\n",
    "            pvalues = dict(zip(groups,p.map(p_appr,[tuple([groups[i],sum([dict_auth_N_ord3.get(x,0) for x in i])])+tuple([dict_authwc_after_year_x[ii].get(round(dict_YEAR_YOUNGEST_START[i],0),0) for ii in i]) for i in groups])))\n",
    "\n",
    "\n",
    "            # max_first_year: groups\n",
    "\n",
    "    #     dict_authworkcount_after_year={'openalex/a21312312':{'1997':28,......}}\n",
    "    #  modify it as follows---- dict_authworkcount_after_year\n",
    "\n",
    "\n",
    "            #tuple_to_validate_order = partial(tuple_to_validate,groups=groups,N=N,deg_a=deg_a)\n",
    "            #params = p.map(tuple_to_validate_order,groups)\n",
    "            #pvalues = dict(zip(groups,p.map(p_appr,params)))\n",
    "\n",
    "        p.close()\n",
    "\n",
    "        n_possible = binom(na,order)\n",
    "        bonf = 0.01/n_possible\n",
    "\n",
    "        temp_df = pd.DataFrame(pvalues.items())\n",
    "        #print(temp_df)\n",
    "        try:\n",
    "            temp_df.columns = ['group','pvalue']\n",
    "        except: temp_df = pd.DataFrame(columns=['group','pvalue'])\n",
    "        #print(temp_df.pvalue.min())\n",
    "        ps = np.sort(temp_df.pvalue)\n",
    "        k = np.arange(1,len(ps)+1)*bonf\n",
    "        try: fdr = k[ps<k][-1] \n",
    "        except: fdr = 0\n",
    "        if approximate: temp_df['w'] = temp_df.group.apply(lambda x: groups[x])\n",
    "        temp_df['fdr'] = temp_df['pvalue']<bonf\n",
    "    #     temp_df['ni'] = temp_df['group'].apply(lambda x: tuple([deg_a[ii] for ii in x]))\n",
    "        temp_df['ni'] = temp_df['group'].apply(lambda x: tuple([dict_authwc_after_year_x[ii].get(round(dict_YEAR_YOUNGEST_START[x],0),list(dict_authwc_after_year_x[ii].items())[0][1]) for ii in x]))\n",
    "\n",
    "\n",
    "        temp_df['N'] = temp_df['group'].apply(lambda i: sum([dict_auth_N_ord3[x] for x in i]))\n",
    "    #         svh_dfs.append(temp_df.query('fdr'))\n",
    "\n",
    "        significant_cores3=temp_df.query('fdr')\n",
    "        value=False;\n",
    "        nonsignificant_cores3=temp_df.query('fdr== @value')\n",
    "        PAPERS_TOGETHER=2\n",
    "        significant_cores3_sample=significant_cores3[significant_cores3['w']>PAPERS_TOGETHER]\n",
    "        nonsignificant_cores3_sample=nonsignificant_cores3\n",
    "        s_groups_order = temp_df.query('fdr').group.tolist()\n",
    "        s_groups.extend(s_groups_order)\n",
    "\n",
    "    #     nonsignificant_cores3_sample=nonsignificant_cores3.sample(n=10*significant_cores3_sample.shape[0], random_state=12)\n",
    "\n",
    "        path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "        import pickle\n",
    "        with open(path_career+'significant_cores3_size'+str(order)+'(whole).pkl', 'wb') as f:\n",
    "            pickle.dump(significant_cores3_sample, f)    \n",
    "        with open(path_career+'significant_non_cores3_size'+str(order)+'(whole).pkl', 'wb') as f:\n",
    "            pickle.dump(nonsignificant_cores3_sample, f)    \n",
    "        print(len(groups_higher_order),temp_df.fdr.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6c707-5b51-4af0-9aea-8566905c026d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21347d1-1550-42f5-b03e-8f0a0b7c0a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105459957\n",
      "9\n",
      "9 ----  0.0\n",
      "drop\n",
      "301587\n",
      "dropped\n",
      "0 65979031383978755.0, time estimate: 0.0000\n",
      "8 ----  125.42\n",
      "drop\n",
      "2664922\n",
      "dropped\n",
      "0 164342648399465427.74, time estimate: 0.0111\n",
      "7 ----  322.35\n",
      "drop\n",
      "12388468\n",
      "dropped\n",
      "0 3199721422116116112.34, time estimate: 0.0343\n",
      "6 ----  919.88\n",
      "drop\n",
      "35619769\n",
      "dropped\n",
      "0 5720023827907475298.76, time estimate: 0.0883\n",
      "5 ----  2146.16\n",
      "drop\n",
      "69285508\n",
      "dropped\n",
      "0 9568006535863748552.06, time estimate: 0.15592\n",
      "4 ----  3681.46\n",
      "drop\n",
      "95828544\n",
      "dropped\n",
      "0 1633191127592547776.5, time estimate: 0.222158\n",
      "3 ----  4849.4\n",
      "drop\n",
      "95095550\n",
      "dropped\n",
      "0 2418959058277175775.24, time estimate: 0.22264\n",
      "2 ----  4760.85\n",
      "drop\n",
      "60956206\n",
      "dropped\n",
      "0 2652966041193574528.4, time estimate: 0.155516\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stasrt_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8b249cd81ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_svs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new_by_papers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict_auth_N_ord3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict_authwc_after_year_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict_firstpub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapproximate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# all_cores5=get_svs(df_new_by_papers[['a','b']],dict_auth_N_ord5,min_order=2,max_order=0,approximate=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time elasped='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstasrt_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stasrt_time' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "# from svs2 import *\n",
    "get_svs(df_new_by_papers[['a','b']],dict_auth_N_ord3,dict_authwc_after_year_x,dict_firstpub,min_order=2,max_order=10,approximate=True)\n",
    "# all_cores5=get_svs(df_new_by_papers[['a','b']],dict_auth_N_ord5,min_order=2,max_order=0,approximate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee844ca-35a2-4ff8-a766-cc3eb91c491f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf182829-d282-462f-9f83-f7734bc4607e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930b891-b3ba-4597-8828-4bab66be4662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2394aa9-b270-4979-b34c-c2f46cc662f7",
   "metadata": {},
   "source": [
    "# Calculation of pubyears, chronogical ordering, c5, diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4cef3a-46bb-450c-8f96-e51f2c3c07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pda\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 8, 'font.style': 'normal', 'font.family':'serif'})\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "def simpleaxis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    plt.xticks(fontsize=ff-4)\n",
    "    plt.yticks(fontsize=ff-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69455603-47c1-4419-877c-c6e6ca720fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133560d-5396-4645-b3e0-ce153774fa25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756274a-91e3-4e08-bb99-b8d784471531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b69721c0-4cbb-499c-8269-bd6075ae75ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "significant_cores3={}\n",
    "PAPERS_TOGETHER=3\n",
    "\n",
    "for gsize in range(2,10):\n",
    "    print(gsize,end='\\r')\n",
    "#     with open(path_career+'significant_cores3_size'+str(gsize)+'_v2.pkl', 'rb') as f:\n",
    "    with open(path_career+'significant_cores3_size'+str(gsize)+'(whole).pkl', 'rb') as f:\n",
    "        significant_cores3[gsize]=pickle.load(f) \n",
    "    significant_cores3[gsize]=significant_cores3[gsize][significant_cores3[gsize]['w']>PAPERS_TOGETHER]\n",
    "    significant_cores3[gsize]['size']=gsize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb8d6f73-ecfc-4fa5-8b12-093fdb2b4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "with open(path_career+'dict_auth_to_paper(whole).pkl', 'rb') as f:\n",
    "    dict_auth_to_paper=pickle.load(f) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "457ff634-9a50-4e4f-909e-ac9e89ba44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.99985444900863610.94, time estimate: 0.0000\n",
      " 247337 \n",
      "\n",
      "3\n",
      "0.99997572874444810.26, time estimate: 0.00113\n",
      " 329609 \n",
      "\n",
      "4\n",
      "0.99972177015165439.81, time estimate: 0.00011\n",
      " 262374 \n",
      "\n",
      "5\n",
      "0.99921893937353566.16, time estimate: 0.00011\n",
      " 111388 \n",
      "\n",
      "6\n",
      "0.99925769428424592.78, time estimate: 0.000\n",
      " 35027 \n",
      "\n",
      "7\n",
      "0.99374899823689691.32, time estimate: 0.000\n",
      " 12479 \n",
      "\n",
      "8\n",
      "0.9909909909909910.6, time estimate: 0.0.00\n",
      " 4441 \n",
      "\n",
      "9\n",
      "0.9575923392612860.25, time estimate: 0.000\n",
      " 1463 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_ic = time.time();\n",
    "\n",
    "for gsize in range(2,10):\n",
    "    t_ic = time.time();\n",
    "    path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "    \n",
    "    print(gsize)\n",
    "    papers_shared=[]\n",
    "    ind_papers_shared=[0]\n",
    "    ind_=0\n",
    "    it=0\n",
    "\n",
    "    for group in significant_cores3[gsize]['group']:\n",
    "        x=[]\n",
    "        for auth in group:\n",
    "            x.append(dict_auth_to_paper[auth])\n",
    "            y=x[0]\n",
    "            for it1 in range(1,len(x)-1):\n",
    "                y=set(y) & set(x[it1])\n",
    "        papers_shared.append(y)\n",
    "        ind_=ind_+len(y)\n",
    "        \n",
    "        it=it+1\n",
    "        if it%100==0:\n",
    "            t_oc = time.time();\n",
    "            frac=(it/len(significant_cores3[gsize]['group']))\n",
    "            prog=str(frac)+str(round(t_oc-t_ic,2))+', time estimate: '+str(round((t_oc-t_ic)/frac/3600,2))\n",
    "            print(prog,end='\\r')\n",
    "\n",
    "    papers_shared=[list(x) for x in papers_shared]    \n",
    "    \n",
    "    if len(papers_shared)>0:\n",
    "        A=np.concatenate(papers_shared)\n",
    "    else:\n",
    "        A=[]\n",
    "    B=[len(x) for x in papers_shared]\n",
    "    C=np.cumsum(B)\n",
    "    C=np.insert(C,0,0)\n",
    "    print('\\n',len(C),'\\n')\n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(A, f)  \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'_ind.pkl', 'wb') as f:\n",
    "        pickle.dump(C, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83475cbc-a2bf-49b3-9fcb-d3d02701b6c2",
   "metadata": {},
   "source": [
    "# pub years + sorting papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1ea8783-08e2-4adb-8cee-37de729515be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "with open(path_career+'dict_pubdate.pkl', 'rb') as f:\n",
    "    dict_pubyear=pickle.load(f) \n",
    "paper_to_pubyear=dict_pubyear;\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26358ea-d757-468a-afec-d81db0f6ee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs 9,0.9562542720437457149.81, time estimate: 0.04161349\r"
     ]
    }
   ],
   "source": [
    "t_ic = time.time();\n",
    "for gsize in range(2,10):\n",
    "\n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'.pkl', 'rb') as f:\n",
    "        papers_by_team=pickle.load(f) \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'_ind.pkl', 'rb') as f:\n",
    "        I=pickle.load(f) \n",
    "    print(gsize,end='\\r')\n",
    "    pub_years=[paper_to_pubyear[x]  if x in paper_to_pubyear.keys() else 0 for x in papers_by_team]\n",
    "    pub_years=np.array(pub_years)\n",
    "\n",
    "\n",
    "    for n in range(len(I)-1):\n",
    "\n",
    "        a=papers_by_team[I[n]:I[n+1]]\n",
    "        b=pub_years[I[n]:I[n+1]]\n",
    "        z=sorted(zip(b,a))\n",
    "        zpapers = [x for _,x in z]\n",
    "        zyears=[_ for _,x in z]\n",
    "        papers_by_team[I[n]:I[n+1]]=zpapers\n",
    "        pub_years[I[n]:I[n+1]]=zyears\n",
    "\n",
    "        if (n+1)%100==0:\n",
    "            t_oc = time.time();\n",
    "            frac=n/len(I)\n",
    "            prog='gs '+str(gsize)+','+str(frac)+str(round(t_oc-t_ic,2))+', time estimate: '+str(round((t_oc-t_ic)/frac/3600,2))\n",
    "            print(prog,end='\\r') \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'_time_ordered.pkl', 'wb') as f:\n",
    "        pickle.dump(papers_by_team, f)  \n",
    "    with open(path_career+'significant_cores(pub_years)'+str(gsize)+'_time_ordered.pkl', 'wb') as f:\n",
    "        pickle.dump(pub_years, f)  \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'ind_time_ordered.pkl', 'wb') as f:\n",
    "        pickle.dump(I, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3745eb-fb69-4f78-9285-064db136ece4",
   "metadata": {},
   "source": [
    "# c5 normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346b25d-ea09-4cc2-be3e-73bcaa138240",
   "metadata": {},
   "source": [
    "# interdisciplinarity / diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ce89274-9671-45b9-8f0d-6b24469473b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_career+'dict_c5_norm.pkl', 'rb') as f:\n",
    "    dict_c5_norm=pickle.load(f) \n",
    "paper_to_c5norm=dict_c5_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b5a7849-ac8b-46a1-afed-37f012bafb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_career+'dict_paper_to_discidiversity.pkl', 'rb') as f:\n",
    "    dict_paper_to_discidiversity=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "173e4ddb-899b-4af0-b079-05dae8ab615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "t_ic = time.time();\n",
    "for gsize in range(2,10):\n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'_time_ordered.pkl', 'rb') as f:\n",
    "        papers_by_team=pickle.load(f) \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'ind_time_ordered.pkl', 'rb') as f:\n",
    "        I=pickle.load(f) \n",
    "\n",
    "    print(gsize,end='\\r')\n",
    "    c5=[paper_to_c5norm[x]  if x in paper_to_c5norm.keys() else 0 for x in papers_by_team]\n",
    "    c5=np.array(c5)\n",
    "\n",
    "    with open(path_career+'significant_cores(c5norm)'+str(gsize)+'_time_ordered.pkl', 'wb') as f:\n",
    "        pickle.dump(c5, f)  \n",
    "        \n",
    "        \n",
    "    pub_diversity=[dict_paper_to_discidiversity[x]  if x in dict_paper_to_discidiversity.keys() else np.nan for x in papers_by_team]\n",
    "    pub_diversity=np.array(pub_diversity)\n",
    "    \n",
    "    with open(path_career+'significant_cores(pub_diversity)'+str(gsize)+'_time_ordered.pkl', 'wb') as f:\n",
    "        pickle.dump(pub_diversity, f)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2446a-c17c-4120-af77-acd4b30d82ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599e75b8-50bc-4e31-83d4-f153fa70428b",
   "metadata": {},
   "source": [
    "# work count union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8269d2e4-3a88-47b0-bada-cf844ecc5cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "t_ic = time.time();\n",
    "first_={}\n",
    "last_={}\n",
    "\n",
    "for gsize in range(2,10):\n",
    "    print(gsize)\n",
    "    first_[gsize]=[]\n",
    "    last_[gsize]=[]\n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'_time_ordered.pkl', 'rb') as f:\n",
    "        papers_by_team=pickle.load(f) \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'ind_time_ordered.pkl', 'rb') as f:\n",
    "        I=pickle.load(f)\n",
    "    with open(path_career+'significant_cores(pub_years)'+str(gsize)+'_time_ordered.pkl', 'rb') as f:\n",
    "        pub_years=pickle.load(f) \n",
    "    for n in range(len(I)-1):        \n",
    "        a=pub_years[I[n]:I[n+1]]\n",
    "        first_[gsize].append(a[0])\n",
    "        last_[gsize].append(a[len(a)-1])\n",
    "        \n",
    "\n",
    "    significant_cores3[gsize]['first_paper_pubyear']=first_[gsize]\n",
    "    significant_cores3[gsize]['last_paper_pubyear']=last_[gsize]\n",
    "\n",
    "    \n",
    "    with open(path_career+'dict_first_paper_pubyear'+str(gsize)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(first_[gsize], f) \n",
    "    with open(path_career+'dict_last_paper_pubyear'+str(gsize)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(last_[gsize], f) \n",
    "\n",
    "\n",
    "#-----------------------------\n",
    "# for gsize in range(2,10):\n",
    "\n",
    "    \n",
    "#     with open(path_career+'dict_first_paper_pubyear'+str(gsize)+'.pkl', 'rb') as f:\n",
    "#         x=pickle.load(f)\n",
    "#     with open(path_career+'dict_last_paper_pubyear'+str(gsize)+'.pkl', 'rb') as f:\n",
    "#         x=pickle.load(f)\n",
    "#     significant_cores3[gsize]['first_paper_pubyear']=x\n",
    "#     significant_cores3[gsize]['last_paper_pubyear']=x\n",
    "\n",
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3934bdb8-4f15-43e9-8c27-ada6820425b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_career+'dict_workcounts_per_year_for_authors.pkl', 'rb') as f:\n",
    "        dict_workcounts_per_year_for_authors=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5d84c18-98e1-412d-9003-ad5f30edb428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000926"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_workcounts_per_year_for_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd47bc-bf2e-4d3e-8576-9db229c54162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eddc395c-8590-4810-96de-adbc0f31e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# List all the JSON files in the current directory\n",
    "# names=path_career+'2authors_papersgrouped/*'\n",
    "# json_files=sorted(glob.glob(names))\n",
    "\n",
    "def calc_workcount_during_active_period(significant_cores3_sample2):\n",
    "    t_ic = time.time();\n",
    "    count_NOTFOUND=0\n",
    "    group=list(significant_cores3_sample2['group'])\n",
    "    from_=list(significant_cores3_sample2['first_paper_pubyear'])\n",
    "    to_=list(significant_cores3_sample2['last_paper_pubyear'])\n",
    "    wcUNION=[]\n",
    "    for it_auth in range(len(group)):\n",
    "        for it_member in range(len(group[it_auth])):\n",
    "            sum_count=0\n",
    "            if group[it_auth][it_member] in dict_workcounts_per_year_for_authors.keys():\n",
    "                for year in dict_workcounts_per_year_for_authors[group[it_auth][it_member]].keys():\n",
    "                    if (year>=from_[it_auth]) and (year<=to_[it_auth]):\n",
    "                        sum_count+=dict_workcounts_per_year_for_authors[group[it_auth][it_member]][year]\n",
    "            else:\n",
    "                count_NOTFOUND+=1\n",
    "        wcUNION.append(sum_count) \n",
    "\n",
    "\n",
    "        if (it_auth+1)%10000==0:\n",
    "            t_oc = time.time();\n",
    "            frac=it_auth/len(group)\n",
    "            prog=str(frac)+str(round(t_oc-t_ic,2))+', time estimate: '+str(round((t_oc-t_ic)/frac/3600,2))\n",
    "            print(prog,end='\\r')\n",
    "    \n",
    "    return wcUNION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8671e353-13e8-4543-a2d0-5f754151ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990951812877087210.61, time estimate: 0.0110.41924664504350686.66, time estimate: 0.00.72813463265454739.45, time estimate: 0.0\r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "json_files=[significant_cores3[k] for k in significant_cores3.keys()]\n",
    "# Create a pool of workers to process the files concurrently\n",
    "with Pool() as pool:\n",
    "    # Apply the processing function to each JSON file concurrently\n",
    "    results = pool.map(calc_workcount_during_active_period, json_files)\n",
    "\n",
    "\n",
    "work_counts_UNION={}\n",
    "for i,result in zip(range(2,10),results):\n",
    "    work_counts_UNION[i]=result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdcebcfb-066b-4696-8e54-9fb8ce6262b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(path_career+'work_counts_UNION.pkl', 'wb') as f:\n",
    "    pickle.dump(work_counts_UNION, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1be69c-4377-413c-9c1e-b6bd77313771",
   "metadata": {},
   "source": [
    "# Paper disciplinary diversity of cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "439709e0-99ae-4af8-a57d-de92ef4da009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs 9,0.956254272043745746.38, time estimate: 0.0137455\r"
     ]
    }
   ],
   "source": [
    "t_ic = time.time();\n",
    "core_diversity={}\n",
    "for gsize in range(2,10):\n",
    "    print(gsize,end='\\r')\n",
    "#     cores=significant_cores3[gsize]\n",
    "#     group=list(cores['group'])\n",
    "    \n",
    "#     with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'_time_ordered.pkl', 'rb') as f:\n",
    "#         papers_by_team=pickle.load(f) \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'ind_time_ordered.pkl', 'rb') as f:\n",
    "        I=pickle.load(f) \n",
    "    with open(path_career+'significant_cores(pub_diversity)'+str(gsize)+'_time_ordered.pkl', 'rb') as f:\n",
    "        pub_diversity=pickle.load(f) \n",
    "\n",
    "    core_diversity[gsize]=[]\n",
    "    for n in range(len(I)-1):\n",
    "\n",
    "        a=pub_diversity[I[n]:I[n+1]]\n",
    "        core_diversity[gsize].append(np.nanmean(a))\n",
    "        \n",
    "        if (n+1)%100==0:\n",
    "            t_oc = time.time();\n",
    "            frac=n/len(I)\n",
    "            prog='gs '+str(gsize)+','+str(frac)+str(round(t_oc-t_ic,2))+', time estimate: '+str(round((t_oc-t_ic)/frac/3600,2))\n",
    "            print(prog,end='\\r') \n",
    "    significant_cores3[gsize]['core_diversity']=core_diversity[gsize]\n",
    "with open(path_career+'dict_significant_core_diversity.pkl', 'wb') as f:\n",
    "    pickle.dump(core_diversity, f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c78d5ca-8c3a-4fe9-93fa-709782be0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c5=[paper_to_c5norm['https://openalex.org/'+x]  if 'https://openalex.org/'+x in paper_to_c5norm.keys() else 0 for x in A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ee38c-0b7f-42c7-a0f4-a2b0145bc286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8419f3-09b1-495f-9fa7-e6e9b1be827e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c84c6b-a390-4e9c-8a4f-363d2a41da2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d98a22-7582-434a-b0ed-2a542d10514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_authwc_after_year_x['https://openalex.org/A2764379743']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982d0e0-2eb4-43b6-bee7-23daf6266a4e",
   "metadata": {},
   "source": [
    "# Giorgio Parisi's id : \n",
    "Searching cores of individual authors\n",
    "https://openalex.org/A2163147449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79095b0-c572-4567-96b6-c978a31e5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientist='https://openalex.org/A2163147449' # fede\n",
    "# scientist='https://openalex.org/A4353661633' # parisi\n",
    "# scientist='https://openalex.org/A4349481004' # dhar\n",
    "# scientist='https://openalex.org/A4337235076' #Gerardo\n",
    "# scientist='https://openalex.org/A4354965935' # marton \n",
    "# scientist='https://openalex.org/A4359848682' # alex arenas\n",
    "# scientist='https://openalex.org/A4359200259' # timoteo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67d91cb3-8137-46de-99f6-acc165870bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n"
     ]
    }
   ],
   "source": [
    "# list(significant_cores3[size].iloc[ind_Parisi,0])[1]\n",
    "# uas=[]\n",
    "dfshow=pd.DataFrame()\n",
    "it=0;ind_Parisi=[]\n",
    "for gsize in range(2,10):\n",
    "    all_=list(significant_cores3_sample['group'])\n",
    "    print(gsize,it)\n",
    "    for it1 in range(len(all_)):\n",
    "        x=all_[it1]\n",
    "        if scientist in x:\n",
    "            ind_Parisi.append([gsize,it])\n",
    "            it=it+1\n",
    "#             print(x)\n",
    "#             print(significant_cores3[gsize].iloc[it1:it1+1])\n",
    "            dfshow=pd.concat([dfshow,significant_cores3_sample.iloc[it1:it1+1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69e9e831-d004-41be-9543-187d8d71c1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n"
     ]
    }
   ],
   "source": [
    "# # list(significant_cores3[size].iloc[ind_Parisi,0])[1]\n",
    "# # uas=[]\n",
    "# dfshow=pd.DataFrame()\n",
    "# it=0;ind_Parisi=[]\n",
    "# for gsize in range(2,10):\n",
    "#     all_=list(significant_cores3[gsize]['group'])\n",
    "#     print(gsize,it)\n",
    "#     for it1 in range(len(all_)):\n",
    "#         x=all_[it1]\n",
    "#         if scientist in x:\n",
    "#             ind_Parisi.append([gsize,it])\n",
    "#             it=it+1\n",
    "# #             print(x)\n",
    "# #             print(significant_cores3[gsize].iloc[it1:it1+1])\n",
    "#             dfshow=pd.concat([dfshow,significant_cores3[gsize].iloc[it1:it1+1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bcd96547-b749-4dba-8023-5280ef508e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9f1a5fe-c0ed-41b6-805f-9e2f76525145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://openalex.org/A4354922397',\n",
       " 'https://openalex.org/A4356412498',\n",
       " 'https://openalex.org/A4359082251',\n",
       " 'https://openalex.org/A4359200259')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfshow.iloc[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ce20e-409d-41ec-a140-8c679490c75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b6ec3-984d-448a-be6a-61d00341363b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7d46b-eba0-40d6-9f42-367b817dec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "# with open(\"/mnt/sdb1/sandeep/Career Transitions/0_track_open_alex1.txt\", \"a\") as file_object:\n",
    "#     file_object.write('\\n --- WRITING TO PICKLE---\\n')\n",
    "\n",
    "# with open(path_career+'all_cores3_alex.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_cores3, f)  \n",
    "    \n",
    "# # with open(path_career+'all_cores5.pkl', 'wb') as f:\n",
    "# #     pickle.dump(all_cores5, f)  \n",
    "\n",
    "# with open(\"/mnt/sdb1/sandeep/Career Transitions/0_track_open_alex1.txt\", \"a\") as file_object:\n",
    "#     file_object.write('\\n --- DONE ---WRITING TO PICKLE---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee0ed7-7142-4416-a7b9-2fd5cd1ef18f",
   "metadata": {},
   "source": [
    "# Load all_cores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06eec6e-de1c-4fb1-a516-311d03a7594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_cores3=all_cores3.query('fdr')\n",
    "#Using variable\n",
    "value=False\n",
    "nonsignificant_cores3=all_cores3.query('fdr== @value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b311686-3771-4e91-b09d-1cc328355142",
   "metadata": {},
   "source": [
    "## Papers_shared: Validated vs Non-Validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56d671d8-e805-4115-b532-a9c65b71ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_auth_to_paper=df_new_by_papers.groupby('a')['b'].apply(list).to_dict()\n",
    "with open(path_career+'dict_auth_to_paper.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_auth_to_paper, f)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90c9d2e2-e906-4c0d-9ed2-126c09166fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237408532</th>\n",
       "      <td>https://openalex.org/W4231991807</td>\n",
       "      <td>https://openalex.org/A1082899512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45872444</th>\n",
       "      <td>https://openalex.org/W3093603893</td>\n",
       "      <td>https://openalex.org/A111511322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31480290</th>\n",
       "      <td>https://openalex.org/W1902517437</td>\n",
       "      <td>https://openalex.org/A1127130828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99361060</th>\n",
       "      <td>https://openalex.org/W4365479417</td>\n",
       "      <td>https://openalex.org/A114219113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223484886</th>\n",
       "      <td>https://openalex.org/W1902517437</td>\n",
       "      <td>https://openalex.org/A1151749126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29897780</th>\n",
       "      <td>https://openalex.org/W3093603893</td>\n",
       "      <td>https://openalex.org/A55814471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135744114</th>\n",
       "      <td>https://openalex.org/W2915977242</td>\n",
       "      <td>https://openalex.org/A59614959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193404364</th>\n",
       "      <td>https://openalex.org/W3093603893</td>\n",
       "      <td>https://openalex.org/A616220467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227838610</th>\n",
       "      <td>https://openalex.org/W4366255002</td>\n",
       "      <td>https://openalex.org/A675397527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24394489</th>\n",
       "      <td>https://openalex.org/W4353018855</td>\n",
       "      <td>https://openalex.org/A87528843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2787 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          a                                 b\n",
       "237408532  https://openalex.org/W4231991807  https://openalex.org/A1082899512\n",
       "45872444   https://openalex.org/W3093603893   https://openalex.org/A111511322\n",
       "31480290   https://openalex.org/W1902517437  https://openalex.org/A1127130828\n",
       "99361060   https://openalex.org/W4365479417   https://openalex.org/A114219113\n",
       "223484886  https://openalex.org/W1902517437  https://openalex.org/A1151749126\n",
       "...                                     ...                               ...\n",
       "29897780   https://openalex.org/W3093603893    https://openalex.org/A55814471\n",
       "135744114  https://openalex.org/W2915977242    https://openalex.org/A59614959\n",
       "193404364  https://openalex.org/W3093603893   https://openalex.org/A616220467\n",
       "227838610  https://openalex.org/W4366255002   https://openalex.org/A675397527\n",
       "24394489   https://openalex.org/W4353018855    https://openalex.org/A87528843\n",
       "\n",
       "[2787 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_by_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37deace0-a33c-4a8b-a88d-80ca61ca565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(path_career+'dict_auth_to_paper.pkl', 'rb') as f:\n",
    "    dict_auth_to_paper=pickle.load(f) \n",
    "for gsize in range(2,8):\n",
    "    t_ic = time.time();\n",
    "    path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "    \n",
    "    print(gsize)\n",
    "    papers_shared=[]\n",
    "    ind_papers_shared=[0]\n",
    "    ind_=0\n",
    "    it=0\n",
    "\n",
    "    for group in significant_cores3[gsize]['group']:\n",
    "        x=[]\n",
    "        for auth in group:\n",
    "            x.append(dict_auth_to_paper[auth])\n",
    "            y=x[0]\n",
    "            for it1 in range(1,len(x)-1):\n",
    "                y=set(y) & set(x[it1])\n",
    "        papers_shared.append(y)\n",
    "        ind_=ind_+len(y)\n",
    "        \n",
    "        it=it+1\n",
    "        if it%100==0:\n",
    "            t_oc = time.time();\n",
    "            frac=(it/len(significant_cores3[gsize]['group']))\n",
    "            prog=str(frac)+str(round(t_oc-t_ic,2))+', time estimate: '+str(round((t_oc-t_ic)/frac/3600,2))\n",
    "            print(prog,end='\\r')\n",
    "\n",
    "            \n",
    "    A=np.concatenate(papers_shared)\n",
    "    B=[len(x) for x in papers_shared]\n",
    "    C=np.cumsum(B)\n",
    "    C=np.insert(C,0,0)\n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(A, f)  \n",
    "    with open(path_career+'significant_cores(papers_shared)'+str(gsize)+'_ind.pkl', 'wb') as f:\n",
    "        pickle.dump(C, f)  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c647965-940a-450e-ab16-df375de537a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2093fdf-70e3-4bc7-a4a3-f353342e61a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd30bd9-86b0-4a05-a880-a9e89046e9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ee7f46-acda-4560-896b-4da991924ad0",
   "metadata": {},
   "source": [
    "### distrbution 'w' : valid vs non-valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101ad98-0b2d-4dcd-a44a-1f5d379cf279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w3=np.array(significant_cores3['w'])\n",
    "w3non=np.array(nonsignificant_cores3['w'])\n",
    "gs3=np.array([len(x) for x in np.array(significant_cores3['group'])])\n",
    "gs3non=np.array([len(x) for x in np.array(nonsignificant_cores3['group'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbe8ff-5afe-4b91-be17-d61f36a553bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "plt.rcParams.update({'font.size': 8, 'font.style': 'normal', 'font.family':'serif'})\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "fig = plt.figure(0,figsize=(9, 4.5));\n",
    "for gs in range(2,10):\n",
    "    ind_selct3=np.where(gs3==gs);\n",
    "    ind_selct3non=np.where(gs3non==gs);\n",
    "\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(2, 4, gs-1);\n",
    "    \n",
    "    #     bins_=(max(store_transition1)-min(store_transition1))+1\n",
    "\n",
    "    ax.hist(w3[ind_selct3],bins=30,color='red',density=False,alpha=0.5,label='Validated cores');\n",
    "    ax.hist(w3non[ind_selct3non],bins=30,color='blue',density=False,alpha=0.5,label='Non-validated cores');\n",
    "    ax.set_yscale('log');\n",
    "    ff=10\n",
    "    # ax.set_xscale('log',base=2);\n",
    "    ax.set_xlim([-10,500])\n",
    "    ax.set_xticks([0,100,200,300,400])\n",
    "    ax.set_xticklabels(ax.get_xticks(), rotation = 45)\n",
    "    if gs==2 or gs==6:\n",
    "        ax.set_ylabel('Frequency (w)',fontsize=ff)\n",
    "    ax.set_title('groupsize='+str(gs),fontsize=ff)\n",
    "    if gs>5:\n",
    "        ax.set_xlabel('# shared papers, w',fontsize=ff);\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    \n",
    "ax.legend(fontsize=ff-2,bbox_to_anchor=(.1,0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27485b59-5b3c-49c3-8fb5-54337bf51be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7cdbbd-d135-48ea-a8cc-f2cb13dcbdf4",
   "metadata": {},
   "source": [
    "### percentile shared papers > 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b8609-2b16-4aa4-95aa-0227d807501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# w3=np.array(significant_cores3['w'])\n",
    "# w3non=np.array(nonsignificant_cores3['w'])\n",
    "# gs3=np.array([len(x) for x in np.array(significant_cores3['group'])])\n",
    "# gs3non=np.array([len(x) for x in np.array(nonsignificant_cores3['group'])])\n",
    "\n",
    "# percentile5=[]\n",
    "# percentile10=[]\n",
    "# percentile15=[]\n",
    "# for gs in range(2,10):\n",
    "#     percentile5.append(len(np.where(((gs3==gs) & (w3>=5)))[0])/len(np.where((gs3==gs))[0] ))\n",
    "#     percentile10.append(len(np.where(((gs3==gs) & (w3>=10)))[0])/len(np.where((gs3==gs))[0] ))\n",
    "#     percentile15.append(len(np.where(((gs3==gs) & (w3>=15)))[0])/len(np.where((gs3==gs))[0] ))\n",
    "\n",
    "# #     ind_selct3non=np.where((gs3non==gs) and ());\n",
    "# #     w3non[ind_selct3non]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f0160-97d8-4f38-866f-ac1ec6519dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0,figsize=(4, 2.5));\n",
    "ax = fig.add_subplot(1, 1, 1);\n",
    "ax.bar(np.array(range(2,10))-.2,percentile5,label='$n_{papers}^{filter} \\geq$ 5',alpha=.5,width=.2);\n",
    "ax.bar(np.array(range(2,10)),percentile10,label='$n_{papers}^{filter} \\geq$ 10',alpha=.5,width=.2);\n",
    "ax.bar(np.array(range(2,10))+.2,percentile15,label='$n_{papers}^{filter} \\geq$ 15',alpha=.5,width=.2);\n",
    "ff=10\n",
    "# ax.set_xscale('log',base=2);\n",
    "# ax.set_xlim([-10,500])\n",
    "ax.set_xticks(range(2,10))\n",
    "# ax.set_xticklabels(ax.get_xticks(), rotation = 45)\n",
    "\n",
    "ax.set_title('percentile of validated cores after filter',fontsize=ff)\n",
    "ax.set_xlabel('core size',fontsize=ff)\n",
    "# ax.set_xlabel('# shared papers, w',fontsize=ff);\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "ax.legend(fontsize=ff,bbox_to_anchor=(1,0.5),frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b22d4-58f3-4cda-9d2c-8ea8190e9244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68f177dd-64be-4343-b895-6b6ea11c100f",
   "metadata": {},
   "source": [
    "# Load all_cores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64e2cc-482f-4b89-bc90-3b8174e54c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "# with open(path_career+'all_cores3_alex.pkl', 'rb') as f:\n",
    "#     all_cores3=pickle.load(f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51dbe4-5e2c-4f0d-994d-df662a4273ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant_cores3=all_cores3.query('fdr')\n",
    "# #Using variable\n",
    "# value=False\n",
    "# nonsignificant_cores3=all_cores3.query('fdr== @value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9089b896-1be1-4c9d-a3dd-60746921845a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11c30def-b9a3-40fd-ae53-b50c117c935b",
   "metadata": {},
   "source": [
    "# Load papers shared by cores \n",
    "into (non) singificant cores3 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a187732-4043-4a77-8199-b94b1d99e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "# with open(path_career+'significant_cores__papers_shared.pkl', 'rb') as f:\n",
    "#     significant_cores__papers_shared=pickle.load(f) \n",
    "\n",
    "# with open(path_career+'nonsignificant_cores__papers_shared.pkl', 'rb') as f:\n",
    "#     nonsignificant_cores__papers_shared=pickle.load(f) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33991004-d492-4104-9806-8caf74fb2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant_cores3['papers_shared']=[[auth_inv_map[x] for x in lis] for lis in significant_cores__papers_shared]\n",
    "# nonsignificant_cores3['papers_shared']=[[auth_inv_map[x] for x in lis] for lis in nonsignificant_cores__papers_shared]\n",
    "\n",
    "# with open(path_career+'significant_cores3_alex.pkl', 'wb') as f:\n",
    "#     pickle.dump(significant_cores3, f)  \n",
    "# with open(path_career+'nonsignificant_cores3_alex.pkl', 'wb') as f:\n",
    "#     pickle.dump(nonsignificant_cores3, f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ea595-62eb-4d08-badf-9cf6bafec398",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "with open(path_career+'significant_cores3_alex.pkl', 'rb') as f:\n",
    "    significant_cores3=pickle.load(f) \n",
    "with open(path_career+'nonsignificant_cores3_alex.pkl', 'rb') as f:\n",
    "    nonsignificant_cores3=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea794e97-4d7c-419b-b3ee-7f09a9a7f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc1be5f-2f89-4c09-bf71-6465e466bc93",
   "metadata": {},
   "source": [
    "# Loading citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605fc84-801d-4949-aeb7-78849fd3f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_data+'openalex_ACTIV/paper_citations/paper_citations0000000*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=12)\n",
    "df_citations = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "# names_par=\"/mnt/sdb1/sandeep/openalex_ACTIV/df_paper_auth.parquet\"\n",
    "# df.to_parquet(names_par,index=None)\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a467ba-2d03-457d-a23c-73b362b1f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd518b-47a5-4185-9138-7f0c65e3bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations['paper_id']=[x[3] for x in list(df_citations['paper_id'].str.split('/'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c82e0e-dce7-408b-b91a-abd1cd3cc9fd",
   "metadata": {},
   "source": [
    "## pub_date to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb8096-c106-48a9-911c-d2dd21d36ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paper_id=[];pub_year=[];pub_mon=[];\n",
    "it=0\n",
    "for p,x in zip(df_citations['paper_id'],df_citations['pub_date']):\n",
    "    it+=1\n",
    "    try:\n",
    "        pub_year.append(int(x.split('-')[0]))\n",
    "        pub_mon.append(int(x.split('-')[1]))\n",
    "        paper_id.append(p)\n",
    "    except:\n",
    "        1\n",
    "    if it%1000==0:\n",
    "        print(it/len(df_citations['pub_date']),end='\\r')\n",
    "        \n",
    "\n",
    "pub_year=np.array(pub_year)\n",
    "pub_mon=np.array(pub_mon)\n",
    "pub_date=np.array(pub_year)+np.array(pub_mon/12)\n",
    "# df_citations['pub_date']=pub_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244c5f7-6c8e-442f-9236-6ce3cd2d50e5",
   "metadata": {},
   "source": [
    "## How many citations per paper? \n",
    "And when were they published?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e515a-02be-455c-8fe0-94291ab4603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cites={x:y for x,y in zip(df_citations['paper_id'],df_citations['n_citations'])}\n",
    "dict_dates={x:y for x,y in zip(paper_id,pub_date)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73ef99-9a33-4851-afae-39915687987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9da4ff-bca7-4913-a1a8-e34109289886",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations=[];it=0\n",
    "years=[];\n",
    "\n",
    "for papers in significant_cores3['papers_shared']:\n",
    "    it+=1\n",
    "    citations.append([dict_cites[p] if p in dict_cites.keys() else np.Nan for p in papers])\n",
    "    years.append([dict_dates[p] if p in dict_cites.keys() else np.Nan for p in papers])\n",
    "    if it%1000==0:\n",
    "        print(it/len(significant_cores3['papers_shared']),end='\\r')\n",
    "significant_cores3['citations']=citations\n",
    "significant_cores3['years']=years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29adeb8-ed63-4b01-8b23-e13a1df8e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsignificant_cores3_sample=nonsignificant_cores3.sample(n=significant_cores3.shape[0], random_state=1)\n",
    "citations=[];it=0\n",
    "years=[];\n",
    "for papers in nonsignificant_cores3_sample['papers_shared']:\n",
    "    it+=1\n",
    "    citations.append([dict_cites[p] if p in dict_cites.keys() else np.Nan for p in papers])\n",
    "    years.append([dict_dates[p] if p in dict_cites.keys() else np.Nan for p in papers])\n",
    "    if it%1000==0:\n",
    "        print(it/len(nonsignificant_cores3_sample['papers_shared']),end='\\r')\n",
    "nonsignificant_cores3_sample['citations']=citations\n",
    "nonsignificant_cores3_sample['years']=years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84468f45-5c85-42f1-a0b3-34f5b0e61012",
   "metadata": {},
   "source": [
    "### Unique papers by persisitent teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b66257-18ea-4fab-a894-3e10610c1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPERS_TOGETHER=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023ef16-50f0-455b-aa27-e5abf0aefdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_cores3_sample=significant_cores3[significant_cores3['w']>PAPERS_TOGETHER]\n",
    "ups=[]\n",
    "for x in significant_cores3_sample['papers_shared']:\n",
    "    ups+=x\n",
    "ups=np.unique(ups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f0f1e-5865-478d-835f-1d6af5bc1b47",
   "metadata": {},
   "source": [
    "### Unique papers by non-persisitent teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace17e8-602f-4413-a0cc-05307d4084a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsignificant_cores3_sample=nonsignificant_cores3.sample(n=significant_cores3.shape[0], random_state=1)\n",
    "\n",
    "upns=[]\n",
    "for x in nonsignificant_cores3_sample['papers_shared']:\n",
    "    upns+=x\n",
    "upns=np.unique(upns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0d6e7-8c40-4f55-bf57-50862c80c973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd08c02-a8b0-4783-9c46-d0e091eb116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ups_cites=np.array([dict_cites[p] if p in dict_cites.keys() else np.Nan for p in ups])\n",
    "upns_cites=np.array([dict_cites[p] if p in dict_cites.keys() else np.Nan for p in upns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7332c4c-f2bd-42cd-b437-9a74a78ed4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ups_dates=np.array([dict_dates[p] if p in dict_dates.keys() else np.Nan for p in ups])\n",
    "upns_dates=np.array([dict_dates[p] if p in dict_dates.keys() else np.Nan for p in upns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1af79-8624-4a3c-af32-01907d9e69c9",
   "metadata": {},
   "source": [
    "#### relative succes of papers by publication year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bef351-4c92-47b4-bf60-7d4db6324f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "yi=1970;yf=2022;years=list(np.linspace(yi,yf,yf-yi+1))\n",
    "ups_m=[];ups_err=[]\n",
    "upns_m=[];upns_err=[]\n",
    "ff=10\n",
    "for Y in years:\n",
    "#     inds=np.where((ups_dates<=Y+1) & (ups_dates>=Y) & (ups_cites>0))[0]\n",
    "#     indns=np.where((upns_dates<=Y+1) & (upns_dates>=Y) & (upns_cites>0))[0]\n",
    "    inds=np.where((ups_dates<=Y+1) & (ups_dates>=Y-1))[0]\n",
    "    indns=np.where((upns_dates<=Y+1) & (upns_dates>=Y-1))[0]\n",
    "#     print(Y,', persistent= ',np.mean(ups_cites[inds]),', non= ',np.mean(upns_cites[indns]))\n",
    "    ups_m.append(np.nanmean(ups_cites[inds]))\n",
    "    ups_err.append(np.power(np.nanvar(ups_cites[inds]),.5)/np.power(len(inds),0.5))\n",
    "    upns_m.append(np.nanmean(upns_cites[indns]))\n",
    "    upns_err.append(np.divide(np.power(np.nanvar(upns_cites[inds]),.5),np.power(len(indns),0.5)))\n",
    "    \n",
    "fig = plt.figure(0,figsize=(6, 2));\n",
    "ax = fig.add_subplot(1, 1, 1);\n",
    "ini_=0;alpha=.5\n",
    "lw=1.5\n",
    "ms=2\n",
    "\n",
    "# ax.plot(years[ini_:],erc[ini_:],'-',markersize=ms,lw=lw,color='royalblue',alpha=alpha)\n",
    "y=ups_m.copy();x=years.copy();y_err=ups_err.copy()\n",
    "ax.errorbar(x, y, y_err , mfc='w',mec='w', ms=0, lw=lw,mew=lw,color='royalblue',ecolor='royalblue', alpha=alpha,label=r'persistent')\n",
    "# ci = 1.96 * np.std(y)/np.sqrt(len(y))\n",
    "# ax.plot(x,y)\n",
    "# ax.fill_between(x, (y-ci), (y+ci), color='b', alpha=.1)\n",
    "\n",
    "# ax.plot(xxxx[ini_:],nsf[ini_:],'-',markersize=ms,lw=lw,color='indianred',alpha=alpha)\n",
    "y=upns_m.copy();x=years.copy();y_err=upns_err.copy()\n",
    "ax.errorbar(x,y,y_err , mfc='w',mec='w', ms=0,lw=lw, mew=lw,color='indianred',ecolor='indianred',alpha=alpha,label=r'non-persistent')\n",
    "# ci = 1.96 * np.std(y)/np.sqrt(len(y))\n",
    "# ax.plot(x,y)\n",
    "# ax.fill_between(x, (y-ci), (y+ci), color='b', alpha=.1)\n",
    "\n",
    "\n",
    "# ff=10\n",
    "\n",
    "# labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "\n",
    "ax.set_xlabel('publication year',fontsize=ff*1)\n",
    "ax.set_ylabel('citations until 2022',fontsize=ff*1)\n",
    "\n",
    "# ax.set_xticks(np.linspace(2,16,8))\n",
    "ax.legend(bbox_to_anchor=(.6,.7),frameon=False,fontsize=ff*.9)\n",
    "plt.xticks(fontsize=ff)\n",
    "plt.yticks(fontsize=ff)\n",
    "\n",
    "simpleaxis(ax)\n",
    "# plt.savefig(path_codes+'figs/fig2_collab_vs_age.png',dpi=300, bbox_inches = \"tight\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225184e-b90f-4477-a12e-807b62ce792f",
   "metadata": {},
   "source": [
    "## Loading references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb55d0-da24-402b-b5e2-fb6070693040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_data+'openalex_ACTIV/paper_ref/paper_refs*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=15)\n",
    "df = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "# names_par=\"/mnt/sdb1/sandeep/openalex_ACTIV/df_paper_auth.parquet\"\n",
    "# df.to_parquet(names_par,index=None)\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd18d-4a3e-470f-a954-e22dbe8b056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['paper_id']=[x[3] for x in list(df['paper_id'].str.split('/'))]\n",
    "# df['ref_works']=[x[3] for x in list(df['ref_works'].str.split('/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04447f61-cda6-496a-8e41-e3698900a6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df296680-a01e-45a3-92ec-2917bce83b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(['ref_works'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1b408-cf92-4b55-8611-5ad57252469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_grouped=df.iloc[1060:2000].groupby(['ref_works'])['paper_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc018ca3-8858-485d-9f34-a06c509e389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc914f3-8fa4-49f2-a02c-ae17fee636dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print([len(df_ref_grouped.iloc[x:x+1][0])for x in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ac83a-bbb3-46cb-b8f5-7f81a7543b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=8\n",
    "print(df_ref_grouped.index[x])\n",
    "\n",
    "print(df_ref_grouped.iloc[x:x+1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f5b6a-bcf0-4bd6-814f-00055271e2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91030e7b-0414-4659-86df-905600c32178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # work_=df_ref_grouped.index[x]\n",
    "# url='https://api.openalex.org/works?filter=cites:'+work_\n",
    "# headers = {\n",
    "#     'User-Agent': 'chowdhary_sandeep',\n",
    "#     'From': 'chowdhary_sandeep@phd.ceu.edu'  # This is another valid field\n",
    "# }\n",
    "# response = requests.get(url, headers=headers)\n",
    "# response.raise_for_status()  # raises exception when not a 2xx response\n",
    "# response=response.json()\n",
    "# print(response['meta']['count'])\n",
    "\n",
    "def get_citers(work_):\n",
    "\n",
    "    url='https://api.openalex.org/works?filter=cites:'+work_\n",
    "    headers = {\n",
    "        'User-Agent': 'chowdhary_sandeep',\n",
    "        'From': 'chowdhary_sandeep@phd.ceu.edu'  # This is another valid field\n",
    "    }\n",
    "\n",
    "\n",
    "    new_url__=url\n",
    "\n",
    "    # get first page\n",
    "\n",
    "    cursor='*'\n",
    "    works_=[]\n",
    "    try:\n",
    "        response = requests.get(new_url__+'&per-page=200&cursor='+cursor,headers=headers)\n",
    "        response.raise_for_status()  # raises exception when not a 2xx response\n",
    "    except:\n",
    "        response = requests.get(new_url__+'&per-page=50&cursor='+cursor,headers=headers)\n",
    "        response.raise_for_status()  # raises exception when not a 2xx response\n",
    "\n",
    "    if response.status_code != 204:\n",
    "        res= response.json()\n",
    "        LL=res['meta']['count']\n",
    "        works_.append(res)\n",
    "        it=0\n",
    "\n",
    "        # get all other pages\n",
    "        while not(res['meta']['next_cursor'] is None):\n",
    "            it+=1\n",
    "            print(it*200/LL,end='\\r')\n",
    "            cursor=res['meta']['next_cursor']\n",
    "            try:\n",
    "                response = requests.get(new_url__+'&per-page=200&cursor='+cursor,headers=headers)\n",
    "                response.raise_for_status()  # raises exception when not a 2xx response\n",
    "\n",
    "            except:\n",
    "                response = requests.get(new_url__+'&per-page=50&cursor='+cursor,headers=headers)\n",
    "                response.raise_for_status()  # raises exception when not a 2xx response\n",
    "            if response.status_code != 204:\n",
    "#                             res= response.json()                            \n",
    "                res = json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "                if len(res['results'])>0:\n",
    "                    works_.append(res)\n",
    "\n",
    "        career_=[]\n",
    "        for it in range(len(works_)):\n",
    "            career_=career_+(works_[it]['results'])\n",
    "        return career_\n",
    "    else:\n",
    "        return 'NA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e0966-9207-4d0d-a2da-88d90d7c6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it=0\n",
    "\n",
    "# for work_ in ups:\n",
    "#     it+=1\n",
    "#     all_citers=get_citers(work_)\n",
    "#     print(it/len(ups),end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3fdf1-5927-4594-a8ee-f628621807cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_citers_=[all_citers[it]['id'].split('/')[3].strip() for it in range(len(all_citers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45efc0-2cc1-4600-a926-a1c1eadcb9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_citers=[response['results'][it]['id'].split('/')[3].strip() for it in range(len(response['results']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b8e7f-df36-4b4a-9fc7-ff9fdf40e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(snapshot_citers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea70db-36c9-40a4-9c8a-5fd6f53d6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_citers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37177b-fd3f-4e98-90cb-343c11b199b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_citers=list(df_ref_grouped.iloc[x:x+1][0])\n",
    "np.sum([x.strip() in all_citers_ for x in snapshot_citers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b9461-33b0-4caa-8eaa-3f41217d8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "58633075+18460402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99437f3-74a2-49d9-add3-83d030be846f",
   "metadata": {},
   "source": [
    "18460402 total unique paper_ids in BigQuery Table paper_refs\n",
    "77093477\n",
    "\n",
    "58633075\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2626344-d6dc-451d-a4f9-c437e628a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['paper_id']=='https://openalex.org/W2612014884']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced4aa5-601a-4d9e-935f-b191c45fd274",
   "metadata": {},
   "outputs": [],
   "source": [
    "18460402/77093477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1a4cc-2b4b-4224-91b8-dc8b50d7d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "77093477/247544757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14795e17-7f34-4b70-bc9a-453914a2566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "247544757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ca060-dbbd-4d8e-9d32-6c24e3b824a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97a124-3a1d-4200-b8f6-da3b38e5135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "75459916/247543975"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102f874-d411-4108-832c-5f779af59826",
   "metadata": {},
   "source": [
    "# frequent publishing teams are more succesful\n",
    "number of papers by team/ core,  distribution of time between successive papers, \n",
    "distribution of means/variances of the time-gap distribution.\n",
    "\n",
    "\n",
    "\n",
    "SUCCESS OF PERSISTENT TEAMS vs NON-PERSISTENT--\n",
    "- citation counts/ num_papers by team for 2 types\n",
    "    - check inflation corrected by discipline citations, same pub year\n",
    "    - single year, single discipline\n",
    "- paper in high impact journals is another measure of success\n",
    "    - number of papers of all papers in  nature by persistent vs non-persistent\n",
    "    - citations of all papers in  nature by persistent vs non-persistent\n",
    "\n",
    "- number of open_access papers is another dimension (Luca)\n",
    "\n",
    "\n",
    "____________________________________\n",
    "Authors who collaborate with succesful (non) persistent  teams are succesful? \n",
    "- right before entering the team -citations/ 5 years after the collab - status of scientist\n",
    "\n",
    "____________________________________\n",
    "Correlate Success with other team level demographics\n",
    "- physical distance (same university)\n",
    "- discipline distance between  members\n",
    "- frequency of publishing together\n",
    "- past shared success drives future collab?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3722682-8ec0-4035-aca8-5a896cb9e60e",
   "metadata": {},
   "source": [
    "____________________________________________________\n",
    "a paper always features a team which consists of persistent members and non-persistent ones.\n",
    "- Unless all are part of the core \n",
    "- OR non are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0f1ed-ffef-4a1d-aa4d-dc822491e7f1",
   "metadata": {},
   "source": [
    "18460402 total unique paper_ids in BigQuery Table paper_refs\n",
    "77093477\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a00dfc-2f83-46df-814d-b015bbc4f572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67177977-35d6-4669-980f-2477b7f0ceea",
   "metadata": {},
   "source": [
    "## Fig 0: career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c01fea-b63b-42c7-9fd2-4ad70494ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd1d7d-53bd-451b-be86-aaad543145e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e61f9f67-6fd4-4328-89c4-820acb1cd4ea",
   "metadata": {},
   "source": [
    "## Fig 1: career age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98dd5c-dd09-4294-b672-e05d6ac4d42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca43bbf-cebf-4045-b5c0-2b80822c3f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f906724f-4c77-4a28-92f0-787e4b08948e",
   "metadata": {},
   "source": [
    "## Fig 2: number of nature / science papers per team\n",
    "disciplinewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85c7cd1-92b6-439b-98d9-475272299741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d22c7a-5fea-4c90-9339-7c1ffe7dfbdb",
   "metadata": {},
   "source": [
    "## Fig 3: displinary variation in core\n",
    "    - requirements:\n",
    "        a) {auth: discipline scores} (threshold .75), a dictionary\n",
    "            - download table from bigquery, filter by threshold, groupby author, make dictionary\n",
    "            \n",
    "        b) add scores to each core, a column in significant_cores_sample and nonsingi...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ccfaf-ea4b-4804-8cfc-8a54554f991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "names=path_data+'openalex_ACTIV/a*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=5)\n",
    "df_disciplines = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83505ff-a334-4383-98eb-6130828d2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disciplines0=df_disciplines[df_disciplines['clevel']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b17fd-184c-4235-90e7-24a11e3a83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aid=np.array(df_disciplines0['auth_id'])\n",
    "cid=list(df_disciplines0['cid'])\n",
    "ind=np.where(aid[0:len(aid)-1]!=aid[1:len(aid)])[0]\n",
    "\n",
    "dict_aconc={}\n",
    "ind=np.insert(ind,0,-1)\n",
    "ind=np.insert(ind,len(ind),len(aid))\n",
    "for itc in range(len(ind)-1):\n",
    "    print(itc/len(ind),end='\\r')\n",
    "    dict_aconc[aid[ind[itc]+1]]=cid[ind[itc]+1:ind[itc+1]+1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c10f3-69ae-4685-8cad-dfa2f800cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aconc['https://openalex.org/A2106175861']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc5b2c-ab79-4ce8-bda2-dd66b7458305",
   "metadata": {},
   "outputs": [],
   "source": [
    "for core in cores_:\n",
    "    print(core)\n",
    "    print([dict_aconc[x] if x in dict_aconc.keys() else -1 for x in core])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f922fdfa-bc26-4c26-95b2-e8c5b24ced88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores_=np.array(significant_cores3_sample['group'])\n",
    "it=0\n",
    "sig_disp=[]\n",
    "for core in cores_:\n",
    "    it+=1\n",
    "    sig_disp.append([dict_aconc[x] if x in dict_aconc.keys() else -1 for x in core])\n",
    "    print(it/len(cores_),end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78f67f-ff40-451c-9629-7543d9e4b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_cores3_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22bb619-c3af-4ddd-95fc-f5f798d1013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f46b2-972d-4334-b1b8-db13ddbe5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "12550795/df_disciplines.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8fdf4-8213-4d38-b44c-a93e2b13868a",
   "metadata": {},
   "source": [
    "## Fig 4: non-core members \n",
    "    - experts?\n",
    "    - new first-time authors? what is the major channel (core teams or non-core) via which new authorsare included in academia?\n",
    "    - first author?\n",
    "    - qualifications? distance from cores expertise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d49b7d-8536-42c5-8264-9ae52116caf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8560a17-5d20-467c-8fcc-0e65fc695a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdf073-2d17-48b1-8303-22366a1356c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
