{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de858fd-073c-4d87-a2da-886c30df9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 8, 'font.style': 'normal', 'font.family':'serif'})\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "def simpleaxis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    plt.xticks(fontsize=ff-4)\n",
    "    plt.yticks(fontsize=ff-4)\n",
    "\n",
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7639f-6c63-429f-af74-130c2f4581bc",
   "metadata": {},
   "source": [
    "# Load authc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abbba19-eb59-4f9f-b781-897e1c5fa5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.708442833274603\n",
      "None\n",
      "1.7094787433743477\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2authc5/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=5)\n",
    "df = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "dict_authc5=df.set_index('auth_id')['c5'].T.to_dict()\n",
    "with open(path_career+'dict_authc5.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_authc5, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348eb13-fae8-4a12-aa12-71dc393fc157",
   "metadata": {},
   "source": [
    "# Literature popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4673f9a-261c-407c-b36e-f436b602f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.52010865136981\n",
      "None\n",
      "25.521927036345005\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2literaturepopularity/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=5)\n",
    "df = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "literaturepopularity=df.set_index('citing')['c5_avg'].T.to_dict()\n",
    "with open(path_career+'dict_literaturepopularity.pkl', 'wb') as f:\n",
    "    pickle.dump(literaturepopularity, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b9672d-c8da-409d-bdb2-5bcac2a25544",
   "metadata": {},
   "source": [
    "# literature depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc69a4f1-3714-40f4-92c0-d9930db13a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.308283876627684\n",
      "None\n",
      "31.309843335300684\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2literaturedepth/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=5)\n",
    "df = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "literaturedepth=df.set_index('citing')['pubdate_avg'].T.to_dict()\n",
    "with open(path_career+'dict_literaturedepth.pkl', 'wb') as f:\n",
    "    pickle.dump(literaturedepth, f) \n",
    "\n",
    "literaturebreadth=df.set_index('citing')['pubdate_std'].T.to_dict()\n",
    "with open(path_career+'dict_literaturebreadth.pkl', 'wb') as f:\n",
    "    pickle.dump(literaturebreadth, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ccaa546-b7e7-4a3f-a96a-8ea39f0323c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "literaturedepth=df.set_index('citing')['pubdate_avg'].T.to_dict()\n",
    "with open(path_career+'dict_literaturedepth.pkl', 'wb') as f:\n",
    "    pickle.dump(literaturedepth, f) \n",
    "\n",
    "literaturebreadth=df.set_index('citing')['pubdate_std'].T.to_dict()\n",
    "with open(path_career+'dict_literaturebreadth.pkl', 'wb') as f:\n",
    "    pickle.dump(literaturebreadth, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883608b1-fe7d-4355-ac11-a97ef056c552",
   "metadata": {},
   "source": [
    "# Load pairs_first_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719ec293-e1f4-4d4c-9f58-8e209281693f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.170799296349287\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2authpairsfirstlastpub/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=15)\n",
    "# df_workcounts = pd.read_csv(files)\n",
    "df_pairs_firstpubtogether = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "\n",
    "# p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "# df_pairs_firstpubtogether[\"A1A2\"] = df_pairs_firstpubtogether[\"A1\"] +'+'+ df_pairs_firstpubtogether[\"A2\"]\n",
    "# dict_pairs_firstpubtogether = df_pairs_firstpubtogether.set_index('A1A2')[['first_year_together']].to_dict()\n",
    "dict_pairs_firstpubtogether = df_pairs_firstpubtogether.groupby('A1')[['A2','first_year_together','last_year_together']].apply(lambda x: x.set_index('A2').to_dict(orient='index')).to_dict()\n",
    "with open(path_career+'dict_pairs_firstpubtogether.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_pairs_firstpubtogether, f) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc49876-f84e-4b27-9776-23eeb4867e0c",
   "metadata": {},
   "source": [
    "# auth workcounts total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98737034-cf72-495f-afc2-ef25e396b3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.81174374371767\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2authworkcounts/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=3)\n",
    "# df_workcounts = pd.read_csv(files)\n",
    "df_workcounts = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "\n",
    "# p.close()\n",
    "\n",
    "print(toc(start_time))\n",
    "\n",
    "\n",
    "dict_workcounts=df_workcounts.set_index('auth_id')['wc'].T.to_dict()\n",
    "with open(path_career+'dict_workcounts.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_workcounts, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3fad15-40a6-49b0-9566-c1ab89a523b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbf60f31-0f90-4582-b7ba-310e7c46341a",
   "metadata": {},
   "source": [
    "# authors to papers dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec396b1-16ec-499a-85bb-f03e3e7528b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# List all the JSON files in the current directory\n",
    "names=path_career+'2authorsgroupedpapers/*'\n",
    "json_files=sorted(glob.glob(names))\n",
    "\n",
    "# json_files = [f for f in os.listdir('.') if f.endswith('.json')]\n",
    "\n",
    "def process_data(data):\n",
    "    return data\n",
    "\n",
    "def process_json_file(filename):\n",
    "    data=[]\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "        # Process the data here...\n",
    "        processed_data = process_data(data)\n",
    "        return processed_data\n",
    "\n",
    "# Create a pool of workers to process the files concurrently\n",
    "with Pool() as pool:\n",
    "    # Apply the processing function to each JSON file concurrently\n",
    "    results = pool.map(process_json_file, json_files)\n",
    "\n",
    "dict_auth_to_paper={}\n",
    "for result in results:\n",
    "    for res in result:\n",
    "        dict_auth_to_paper[res['auth_id']]=res['papers']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e6e42-8d94-4b51-9801-a3c42e95b499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f2b3f-8f8f-4764-a024-4c22216e7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_career+'dict_auth_to_paper(whole).pkl', 'wb') as f:\n",
    "    pickle.dump(dict_auth_to_paper, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d8823-94fa-45ae-8c59-b430e3cc0a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e097ae65-ffeb-4933-a1c0-3029e13ff9a3",
   "metadata": {},
   "source": [
    "# c5\n",
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0273b39f-901c-42ac-8d77-3c9154f3287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.530694387853146\n",
      "None\n",
      "21.531843692064285\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2c5norm/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=5)\n",
    "df_c5_norm = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "dict_c5_norm=df_c5_norm.set_index('id')['c5_normalized'].T.to_dict()\n",
    "with open(path_career+'dict_c5_norm.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_c5_norm, f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616a122-5e44-477d-998d-cfa57ac85e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8550892a-dec1-47cb-95d3-5109079648bc",
   "metadata": {},
   "source": [
    "# paper pubdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f966eff-0429-4b88-a4fd-b76f832f76f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.554304394871\n",
      "None\n",
      "106.55620150640607\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2paperspubdates/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=5)\n",
    "df_pubdate = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "# names_par=\"/mnt/sdb1/sandeep/open_alex_ACTIV/df_paper_auth.parquet\"\n",
    "# df.to_parquet(names_par,index=None)\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "\n",
    "dict_pubdate=df_pubdate.set_index('id')['pubdate'].T.to_dict()\n",
    "with open(path_career+'dict_pubdate.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_pubdate, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8ae0f-7aae-401f-abc9-b19c154c923f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dca7977-d4f4-4002-b938-c0b4a72bf5c6",
   "metadata": {},
   "source": [
    "# disciplinary diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5507a68f-84b5-4073-8be7-1b3374c6449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.0606624558568\n",
      "None\n",
      "108.0622975602746\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2papersconceptsdiversity/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=15)\n",
    "df = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "# names_par=\"/mnt/sdb1/sandeep/open_alex_ACTIV/df_paper_auth.parquet\"\n",
    "# df.to_parquet(names_par,index=None)\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "dict_=df.set_index('paper_id')['concept_entropy'].T.to_dict()\n",
    "with open(path_career+'dict_paper_to_discidiversity.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225ecf4-9a52-4f00-a5c2-e5b02e1303d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8dd2782-715c-49c4-b123-7edc1bb0bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_=df.set_index('paper_id')['concept_entropy'].T.to_dict()\n",
    "with open(path_career+'dict_paper_to_discidiversity.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38561e2a-0e1b-47cc-a4e5-9543d980691b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70abe883-3bbe-419a-9080-d39c1bc73eed",
   "metadata": {},
   "source": [
    "# c5 within discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5cb6c85-986b-453d-9df1-06376f72a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # \n",
    "# start_time = timeit.default_timer()\n",
    "# names=path_career+'c5_within_discipline/*'\n",
    "# files=sorted(glob.glob(names))\n",
    "\n",
    "# p=Pool(processes=5)\n",
    "# df_c5_within = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "# print(toc(start_time))\n",
    "# # names_par=\"/mnt/sdb1/sandeep/open_alex_ACTIV/df_paper_auth.parquet\"\n",
    "# # df.to_parquet(names_par,index=None)\n",
    "\n",
    "# p.close()\n",
    "# print(toc(start_time))\n",
    "\n",
    "# dict_c5_within=df_c5_within.set_index('cited')['c5'].T.to_dict()\n",
    "# with open(path_career+'dict_c5_within.pkl', 'wb') as f:\n",
    "#     pickle.dump(dict_c5_within, f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ebb16b-9526-4f1c-b41b-79de700daaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # \n",
    "# start_time = timeit.default_timer()\n",
    "# names=path_career+'c5_within_lvl1/*'\n",
    "# files=sorted(glob.glob(names))\n",
    "\n",
    "# p=Pool(processes=5)\n",
    "# df_c5_within_lvl1 = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "# print(toc(start_time))\n",
    "\n",
    "\n",
    "# p.close()\n",
    "# print(toc(start_time))\n",
    "\n",
    "# dict_c5_within_lvl1=df_c5_within_lvl1.set_index('cited')['c5'].T.to_dict()\n",
    "# with open(path_career+'dict_c5_within_lvl1.pkl', 'wb') as f:\n",
    "#     pickle.dump(dict_c5_within_lvl1, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d5ea9-003e-46a6-91e8-771a5e76568d",
   "metadata": {},
   "source": [
    "# workcount_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ea9aa8-c2ce-4d6a-b79a-ef3563cd71da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb550122-5493-4bb6-bd46-dd64604ea9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# List all the JSON files in the current directory\n",
    "# names=path_career+'2workcountsperyear_statphy/*'\n",
    "names=path_career+'2workcounts_per_year_for_authors/*'\n",
    "\n",
    "json_files=sorted(glob.glob(names))\n",
    "\n",
    "# json_files = [f for f in os.listdir('.') if f.endswith('.json')]\n",
    "\n",
    "def process_data(data):\n",
    "    return data\n",
    "\n",
    "def process_json_file(filename):\n",
    "    data=[]\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "        # Process the data here...\n",
    "        processed_data = process_data(data)\n",
    "        return processed_data\n",
    "\n",
    "\n",
    "    # Create a pool of workers to process the files concurrently\n",
    "with Pool() as pool:\n",
    "    # Apply the processing function to each JSON file concurrently\n",
    "    results = pool.map(process_json_file, json_files)\n",
    "\n",
    "dict_workcounts={}\n",
    "for result in results:\n",
    "    for res in result:\n",
    "        dict_workcounts[res['auth_id']]={int(year):int(wc) for year,wc in sorted(zip(res['pubyear'],res['wc']))}\n",
    "\n",
    "# with open(path_career+'dict_workcounts_per_year_for_authors_statphy.pkl', 'wb') as f:\n",
    "with open(path_career+'dict_workcounts_per_year_for_authors.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_workcounts, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4496ee0-4ba8-40d2-ac7c-449efc69be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_authwc_after_year_x={}\n",
    "for auth in dict_workcounts.keys():\n",
    "    dict_authwc_after_year_x[auth]={}\n",
    "    totalworks=np.sum(list(dict_workcounts[auth].values()))\n",
    "    wcount=0\n",
    "    for year in range(np.min(list(dict_workcounts[auth].keys())),2024):\n",
    "\n",
    "        dict_authwc_after_year_x[auth][year]=totalworks-wcount\n",
    "        try:\n",
    "            wcount+=dict_workcounts[auth][year]\n",
    "        except:\n",
    "            1\n",
    "# with open(path_career+'dict_authwc_after_year_x_STATPHY.pkl', 'wb') as f:\n",
    "with open(path_career+'dict_authwc_after_year_x.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_authwc_after_year_x, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5b5ba-95fc-447a-98b3-922063defe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d4ead-bddf-4a51-a933-efc447b1cb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ee2fada-06a4-45bc-a59c-5cff82c45177",
   "metadata": {},
   "source": [
    "# dict auth_firstpub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050a1ccb-65bc-4dc5-8179-103c6d0f4e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2793035618960857\n",
      "None\n",
      "2.2804005183279514\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2authorsfirstpubdate/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=4)\n",
    "df_firstpub = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "dict_firstpub=df_firstpub.set_index('aid')['first_pub'].T.to_dict()\n",
    "\n",
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "import pickle\n",
    "with open(path_career+'dict_firstpub.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_firstpub, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df345767-599d-4211-aa7d-bcb551c41c30",
   "metadata": {},
   "source": [
    "# dict_authage2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d506a074-0ddd-4582-a867-1dca7263ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_authage2023={x:2023- dict_firstpub[x] for x in dict_firstpub.keys()}\n",
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "import pickle\n",
    "with open(path_career+'dict_authage2023.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_authage2023, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd37658-3f1c-45f1-95cc-b8a86f58e76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8851776"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_firstpub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4e449-ba03-416a-bbcd-591fae621d69",
   "metadata": {},
   "source": [
    "# 2papersteamsizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94bba119-ab35-4ed1-9ba2-5f331031a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.74788759276271\n",
      "None\n",
      "41.74942532926798\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # # \n",
    "start_time = timeit.default_timer()\n",
    "names=path_career+'2papersteamsizes/*'\n",
    "files=sorted(glob.glob(names))\n",
    "\n",
    "p=Pool(processes=8)\n",
    "df = pd.concat(p.map(pd.read_csv,files),ignore_index=True)\n",
    "print(toc(start_time))\n",
    "\n",
    "p.close()\n",
    "print(toc(start_time))\n",
    "\n",
    "dict_=df.set_index('paper_id')['f0_'].T.to_dict()\n",
    "\n",
    "path_career='/mnt/sdb1/sandeep/openalex_ACTIV/'\n",
    "import pickle\n",
    "with open(path_career+'dict_papersteamsizes.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bcbb4f3-6d7b-4bc0-9574-8b4f63abc6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112034640"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe72e0a-05a7-4ed1-887b-d33aeaa94498",
   "metadata": {},
   "source": [
    "# Author c5 per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcb4da-d6b4-403b-97d9-84aabd81353a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
